cd Langslate
docker compose up -d
http://localhost:3000
ollama api url - OLLAMA = "http://host.docker.internal:11434"

api SEARXNG
api llama3.3 on localhost:11434 running on the H100 provided

